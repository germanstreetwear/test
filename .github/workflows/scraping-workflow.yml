name: Scrape and Save to Firestore

on:
  workflow_dispatch: # Manuelles Auslösen des Workflows
  schedule:
    - cron: '0 3 * * *' # Automatisches Ausführen jeden Tag um 3 Uhr (UTC)

jobs:
  scrape-shop-data:
    runs-on: ubuntu-latest

    steps:
    # 1. Checkout Code
    - name: Checkout Repository
      uses: actions/checkout@v3

    # 2. Set up Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    # 3. Install Dependencies
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # 4. Download WebDriver (z. B. ChromeDriver für Selenium)
    - name: Download ChromeDriver
      run: |
        sudo apt-get update
        sudo apt-get install -y unzip
        wget https://chromedriver.storage.googleapis.com/$(curl -sS https://chromedriver.storage.googleapis.com/LATEST_RELEASE)/chromedriver_linux64.zip
        unzip chromedriver_linux64.zip
        sudo mv chromedriver /usr/local/bin/

    # 5. Run Python Script
    - name: Run Scraper Script
      env:
        GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.FIREBASE_KEY }} # Firebase-Schlüssel als Secret speichern
      run: |
        python scraper.py
